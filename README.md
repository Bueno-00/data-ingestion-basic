ğŸ§  Projeto 01 â€“ Data Ingestion BÃ¡sico (ETL com Azure e Power BI)

ğŸ“˜ VisÃ£o Geral

Este projeto demonstra um processo completo de ingestÃ£o, transformaÃ§Ã£o e carga de dados (ETL/ELT), utilizando Python, SQLite, Azure Blob Storage e Power BI para visualizaÃ§Ã£o.
O objetivo Ã© construir uma pipeline simples, mas funcional, que realiza todas as etapas principais de Engenharia de Dados:

Leitura de dados brutos

Limpeza e transformaÃ§Ã£o

Armazenamento em banco de dados

Upload na nuvem (Azure)

VisualizaÃ§Ã£o dos resultados (Power BI)

Os dados sÃ£o pequenos (apenas 6 vendas de 3 produtos) e servem para demonstrar o fluxo completo de ETL.

ğŸ—‚ Estrutura do Projeto
DATA-ENGINEERING-PORTFOLIO/
â”‚
â”œâ”€â”€ .venv/                     # Ambiente virtual Python
â”‚
â”œâ”€â”€ .vscode/                   # ConfiguraÃ§Ãµes do VSCode
â”‚
â”œâ”€â”€ 01-data-ingestion-basic/
â”‚   â”œâ”€â”€ datasets/              # Dados brutos
â”‚   â”‚   â””â”€â”€ sample_sales.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ outputs/               # Resultados processados
â”‚   â”‚   â”œâ”€â”€ cleaned_sales.csv  # Dados tratados
â”‚   â”‚   â””â”€â”€ sales.db           # Banco SQLite
â”‚   â”‚
â”‚   â”œâ”€â”€ src/                   # CÃ³digos principais
â”‚   â”‚   â”œâ”€â”€ ingest_transform.py  # IngestÃ£o e transformaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ to_sqlite.py         # Armazenamento em banco
â”‚   â”‚   â””â”€â”€ upload_to_azure.py   # Upload para Azure
â”‚   â”‚
â”‚   â”œâ”€â”€ images/                # GrÃ¡ficos do Power BI
â”‚   â”‚   â”œâ”€â”€ x.png
â”‚   â”‚   â”œâ”€â”€ xx.png
â”‚   â”‚   â”œâ”€â”€ xxx.png
â”‚   â”‚   â””â”€â”€ xxxx.png
â”‚   â”‚
â”‚   â”œâ”€â”€ .env                   # Chaves Azure (privado)
â”‚   â”œâ”€â”€ .gitignore             # Arquivos ignorados pelo Git
â”‚   â”œâ”€â”€ requirements.txt       # Bibliotecas
â”‚   â””â”€â”€ README.md              # DocumentaÃ§Ã£o

âš™ï¸ Tecnologias e Ferramentas

Python 3.13+

Pandas â†’ leitura e tratamento dos dados

SQLite3 â†’ banco de dados local

Azure CLI â†’ upload para o Azure Blob Storage

Power BI â†’ visualizaÃ§Ã£o e dashboards

VSCode â†’ ambiente de desenvolvimento

Ambiente Virtual (.venv) â†’ isolamento de dependÃªncias

ğŸ§© Etapas do Processo ETL
1ï¸âƒ£ IngestÃ£o e TransformaÃ§Ã£o (ingest_transform.py)

LÃª o arquivo datasets/sample_sales.csv

Converte datas e tipos de dados

Calcula novas colunas (revenue = price * quantity)

Limpa valores nulos e padroniza nomes de produtos

Exporta os dados tratados em outputs/cleaned_sales.csv

ğŸ“¸ VisualizaÃ§Ã£o no VSCode:


2ï¸âƒ£ Armazenamento no Banco (to_sqlite.py)

Conecta ao SQLite3

Cria o banco sales.db em outputs/

Cria e insere dados na tabela sales

Executa query para sumarizar vendas por produto

ğŸ“¸ Banco de Dados e Query:


3ï¸âƒ£ Upload para Azure (upload_to_azure.py)

LÃª variÃ¡veis do .env:

AZURE_STORAGE_ACCOUNT

AZURE_STORAGE_KEY

AZURE_CONTAINER_NAME

Usa o Azure CLI via comando az storage blob upload

Envia arquivos tratados (cleaned_sales.csv, sales.db) para o Blob Storage

ğŸ“¸ ExecuÃ§Ã£o do Upload via CLI:


4ï¸âƒ£ VisualizaÃ§Ã£o no Power BI

ApÃ³s o upload, os dados sÃ£o consumidos diretamente do Azure e visualizados no Power BI, gerando insights como:

Vendas por produto

Vendas por estado

ğŸ“Š GrÃ¡ficos criados no Power BI:


ğŸ§° Requisitos e InstalaÃ§Ã£o

Instalar dependÃªncias:

pip install -r requirements.txt


Executar o pipeline completo:

# Ativar ambiente virtual
source .venv/Scripts/activate

# 1. IngestÃ£o e transformaÃ§Ã£o
python src/ingest_transform.py

# 2. CriaÃ§Ã£o do banco
python src/to_sqlite.py

# 3. Upload para Azure
python src/upload_to_azure.py

ğŸ” ConfiguraÃ§Ã£o do .env

Antes de rodar o upload, crie o arquivo .env na raiz do projeto com suas credenciais Azure:

AZURE_STORAGE_ACCOUNT=nomedaconta
AZURE_STORAGE_KEY=sua_chave_aqui
AZURE_CONTAINER_NAME=raw-data


âš ï¸ Importante: o arquivo .env estÃ¡ incluÃ­do no .gitignore, por isso nÃ£o serÃ¡ enviado ao GitHub (seguranÃ§a garantida).

ğŸ“Š Power BI â€“ RelatÃ³rios

ApÃ³s carregar os dados no Power BI, foram criadas duas visualizaÃ§Ãµes:

GrÃ¡fico 1 â€“ Vendas por Produto

GrÃ¡fico 2 â€“ Vendas por Estado

Esses grÃ¡ficos demonstram o sucesso do pipeline completo, desde a ingestÃ£o atÃ© a visualizaÃ§Ã£o analÃ­tica.

ğŸ“š Objetivo Educacional

Este projeto foi desenvolvido com fins educacionais e demonstrativos, consolidando conceitos de:

ETL/ELT com Python

TransformaÃ§Ã£o de dados

CriaÃ§Ã£o de banco local

IntegraÃ§Ã£o com nuvem (Azure)

VisualizaÃ§Ã£o com Power BI

ğŸ‘¨â€ğŸ’» Autor

Rafael Bueno
Projeto desenvolvido para estudo prÃ¡tico em Engenharia de Dados.